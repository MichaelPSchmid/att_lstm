# Training Session - 2026-01-21/22

## Ablation Study: Dropout-Vergleich

### Config-Matrix (12 Configs)

| Modell | Ohne Dropout | Mit Dropout | Status |
|--------|--------------|-------------|--------|
| M1 Small Baseline | `m1_small_baseline.yaml` | `m1_small_baseline_dropout.yaml` | ⏳ |
| M2 Small + Simple Attn | `m2_small_simple_attn.yaml` | `m2_small_simple_attn_dropout.yaml` | ⏳ |
| M3 Medium Baseline | `m3_medium_baseline.yaml` | `m3_medium_baseline_dropout.yaml` | ⏳ |
| M4 Medium + Simple Attn | `m4_medium_simple_attn.yaml` | `m4_medium_simple_attn_dropout.yaml` | ⏳ |
| M5 Medium + Additive Attn | `m5_medium_additive_attn.yaml` | `m5_medium_additive_attn_dropout.yaml` | ⏳ |
| M6 Medium + Scaled DP Attn | `m6_medium_scaled_dp_attn.yaml` | `m6_medium_scaled_dp_attn_dropout.yaml` | ⏳ |

### Namenskonvention

```
Basis-Config (kein Suffix) = dropout: 0.0, patience: 5
_dropout Suffix            = dropout: 0.2, patience: 15
```

### Hyperparameter-Settings

| Setting | Ohne Dropout | Mit Dropout |
|---------|--------------|-------------|
| dropout | 0.0 | 0.2 |
| patience | 5 | 15 |
| LR (Small) | 0.001 | 0.001 |
| LR (Medium) | 0.0005 | 0.0005 |

---

## Bisherige Ergebnisse

### M1 Small Baseline (Archiv)

| Konfiguration | Test Accuracy | Test R² | val_loss | Epochen |
|---------------|---------------|---------|----------|---------|
| Ohne Dropout | **82.5%** | **0.860** | 0.0017 | ~14 |
| Mit Dropout 0.2 | ~80.5% | ~0.843 | 0.00188 | ~50+ |

**Erkenntnis:** Dropout verursacht Underfitting bei kleinen Modellen (~85K Parameter).

---

## Trainingskommandos

### Ohne Dropout (Basis)
```bash
python scripts/train_model.py --config config/model_configs/m1_small_baseline.yaml
python scripts/train_model.py --config config/model_configs/m2_small_simple_attn.yaml
python scripts/train_model.py --config config/model_configs/m3_medium_baseline.yaml
python scripts/train_model.py --config config/model_configs/m4_medium_simple_attn.yaml
python scripts/train_model.py --config config/model_configs/m5_medium_additive_attn.yaml
python scripts/train_model.py --config config/model_configs/m6_medium_scaled_dp_attn.yaml
```

### Mit Dropout (Ablation)
```bash
python scripts/train_model.py --config config/model_configs/m1_small_baseline_dropout.yaml
python scripts/train_model.py --config config/model_configs/m2_small_simple_attn_dropout.yaml
python scripts/train_model.py --config config/model_configs/m3_medium_baseline_dropout.yaml
python scripts/train_model.py --config config/model_configs/m4_medium_simple_attn_dropout.yaml
python scripts/train_model.py --config config/model_configs/m5_medium_additive_attn_dropout.yaml
python scripts/train_model.py --config config/model_configs/m6_medium_scaled_dp_attn_dropout.yaml
```

---

## Paper-Dokumentation

### Empirische Begründung für unterschiedliche Settings

**Analyse der Loss-Kurven (M1):** Train- und Val-Loss liefen parallel → kein Overfitting.
Der vermeintliche "Einbruch" war durch zu hohe LR (0.005) verursacht, nicht durch Overfitting.

### Paper-Formulierung (Entwurf)

> "To ensure fair comparison, we conducted an ablation study on dropout regularization.
> Each model was trained both with and without dropout (0.2). Results showed that
> the effect of dropout varies by model size: smaller models (~85K parameters)
> achieved better performance without dropout, while larger models (~600K parameters)
> [results pending]. All hyperparameters except dropout were kept constant within
> each model size category."

### Erwartete Ablation-Tabelle für Paper

| Model | Size | Dropout | Accuracy | R² | Bemerkung |
|-------|------|---------|----------|-----|-----------|
| M1 | Small | 0.0 | 82.5% | 0.86 | ✅ Archiv |
| M1 | Small | 0.2 | 80.5% | 0.84 | ✅ Archiv |
| M2 | Small | 0.0 | ? | ? | TODO |
| M2 | Small | 0.2 | ? | ? | TODO |
| M3 | Medium | 0.0 | ? | ? | TODO |
| M3 | Medium | 0.2 | ? | ? | TODO |
| M4 | Medium | 0.0 | ? | ? | TODO |
| M4 | Medium | 0.2 | ? | ? | TODO |
| M5 | Medium | 0.0 | ? | ? | TODO |
| M5 | Medium | 0.2 | ? | ? | TODO |
| M6 | Medium | 0.0 | ? | ? | TODO |
| M6 | Medium | 0.2 | ? | ? | TODO |

---

## Nächste Schritte

1. [ ] Alle 12 Modelle trainieren
2. [ ] Ergebnisse in Tabelle eintragen
3. [ ] Statistische Signifikanz prüfen (falls nötig mehrere Seeds)
4. [ ] Paper-Ablation-Tabelle finalisieren
